{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import mxnet as mx\n",
    "\n",
    "# Faz o download do dataset MNIST\n",
    "mnist = mx.test_utils.get_mnist()\n",
    "\n",
    "# Inicializa gerador de números aleatórios \n",
    "mx.random.seed(42)\n",
    "\n",
    "# Define o contexto computacional, se a GPU estiver disponivel vai executar nela poquq é mais rápido, senão na CPU\n",
    "ctx_comp = mx.gpu() if mx.test_utils.list_gpus() else mx.cpu()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lote de 100 neurônios\n",
    "tam_lote= 100\n",
    "\n",
    "# Referência1= https://mxnet.incubator.apache.org/api/python/io/io.html\n",
    "# Referência2= http://mxnet.incubator.apache.org/test/versions/0.10/api/python/ndarray.html#module-mxnet.ndarray\n",
    "\n",
    "# A API do NDArray, definida no pacote ndarray (ou simplesmente nd), fornece operações imperativas de tensor na CPU / GPU.\n",
    "# Um NDArray representa um array de tamanho fixo e multidimensional.\n",
    "\n",
    "# Dado array= (tamanho lote, número de canais, largura, altura)\n",
    "\n",
    "#inicializou e embaralhou o vetor de imagens de teste e seus labels(onde diz qual é o número que está na imagem) \n",
    "dados_treino = mx.io.NDArrayIter(mnist['train_data'], mnist['train_label'], tam_lote, shuffle=True)\n",
    "print(dados_treino.provide_data)\n",
    "print(dados_treino.provide_label)\n",
    "\n",
    "#inicializou o vetor de teste\n",
    "dados_teste = mx.io.NDArrayIter(mnist['test_data'], mnist['test_label'], tam_lote)\n",
    "print(dados_teste.provide_data)\n",
    "print(dados_teste.provide_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MULTILAYER PERCEPTRON (MPL)\n",
    "\n",
    "# Criando um local reservado para o dado de entrada\n",
    "dado_entrada = mx.sym.var('data')\n",
    "\n",
    "# \"Achata\" os pixels, passa a imagem de 4D pra 2D (tamanho lote, número de canais(1) * width (28) * height (28))\n",
    "dato_entrada = mx.sym.flatten(data=dado_entrada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seta o número de neurônios da camada 1 \n",
    "camada1  = mx.sym.FullyConnected(data=dado_entrada, num_hidden=128)\n",
    "\n",
    "# Seta a activation function usada na camada 1\n",
    "resultado1 = mx.sym.Activation(data=camada1, act_type=\"relu\")\n",
    "\n",
    "# Seta o número de neurônios da camada 2\n",
    "camada2  = mx.sym.FullyConnected(data=resultado1, num_hidden = 64)\n",
    "\n",
    "# Seta a activation function usada na camada 2\n",
    "resultado2 = mx.sym.Activation(data=camada2, act_type=\"relu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST tem 10 classes (0, 1, 2, 3, 4, 5, 6, 7, 8, 9)\n",
    "\n",
    "# O dado da camada 3 é a camada  2 com a função de ativação(RELU) aplicada\n",
    "camada3  = mx.sym.FullyConnected(data=camada2, num_hidden=10)\n",
    "\n",
    "# Softmax com cross entropy loss\n",
    "# Softmax= Ela força a saída de uma rede neural a representar a probabilidade dos dados serem de uma das classes definidas.\n",
    "# Cross-entropy= Em suma, a entropia cruzada é positiva e tende a zero, à medida que o neurônio melhora a computação da saída desejada, y, para todas as entradas de treinamento, x \n",
    "mlp  = mx.sym.SoftmaxOutput(data=camada3, name='softmax')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![png](https://raw.githubusercontent.com/dmlc/web-data/master/mxnet/image/mlp_mnist.png)\n",
    "\n",
    "**Figure 1:** MLP network architecture for MNIST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TREINAMENTO\n",
    "\n",
    "# Stochastic gradient descent (SGD)= Busca minimizar a função de custo escolhendo os melhores parâmetros de entrada dos que tem disponível.\n",
    "\n",
    "import logging\n",
    "logging.getLogger().setLevel(logging.DEBUG)  # Para mostrar o progresso do modelo\n",
    "\n",
    "# Cria um módulo de treino no contexto computacional atual(GPU ou CPU)\n",
    "mlp_model = mx.mod.Module(symbol=mlp, context=ctx_comp)\n",
    "\n",
    "# Parâmetros do modelo\n",
    "mlp_model.fit(dados_treino, # Dados de treino\n",
    "              \n",
    "     eval_data=dados_teste, # Dados para avaliação\n",
    "              \n",
    "     optimizer='sgd', # Usa o método de otimização SGD\n",
    "              \n",
    "     optimizer_params={'learning_rate':0.1}, # Controla o tamanho da passo que o otimizador toma em busca de uma solução.\n",
    "     # Este parâmetro informa ao otimizador até onde mover os pesos na direção do gradiente para um mini-lote.\n",
    "              \n",
    "      eval_metric='acc', # Mostra a precisão do treino\n",
    "              \n",
    "      batch_end_callback = mx.callback.Speedometer(tam_lote,100), # Mostra progresso de treino para cada 100 lotes de 100 imagens\n",
    "              \n",
    "      num_epoch=10) # Passa 10 vezes o dataset inteiro, \n",
    "                    # A cada passada, os pesos são atualizados, o aprendizado ocorre e o custo, ou a taxa de erros, diminui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teste = mx.io.NDArrayIter(mnist['test_data'], None, tam_lote) # Vetor setado com as imagens, sem os labels para teste\n",
    "\n",
    "prob = mlp_model.predict(teste) # Calcula a probabilidade de cada imagem das 10000, ser de cada uma das 10 classes\n",
    "\n",
    "assert prob.shape == (10000, 10) # Verificação em tempo de execução de uma condição qualquer. Se a condição não for verdadeira, \n",
    "                                 # uma exceção AssertionError acontece e o programa para"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teste = mx.io.NDArrayIter(mnist['test_data'], mnist['test_label'], tam_lote)\n",
    "\n",
    "# Previsão da precisão do modelo mlp\n",
    "precisao = mx.metric.Accuracy()\n",
    "mlp_model.score(teste, precisao)\n",
    "print(precisao)\n",
    "assert precisao.get()[1] > 0.96, \"A precisão alcançada (%f) é menor do que a esperada (0.96)\" % precisao.get()[1]"
   ]
  }
 ],
 "metadata": {
  "display_name": "",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "name": ""
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
